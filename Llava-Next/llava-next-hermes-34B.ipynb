{
  "cells": [
    {
      "cell_type": "code",
      "id": "4iAvW5KKWCLjCd9SnGUIVzQW",
      "metadata": {
        "tags": [],
        "id": "4iAvW5KKWCLjCd9SnGUIVzQW"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install bitsandbytes\n",
        "!pip install accelerate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os._exit(00)"
      ],
      "metadata": {
        "id": "Hc1uFlbsPc2k"
      },
      "id": "Hc1uFlbsPc2k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "import requests\n",
        "from transformers import LlavaNextForConditionalGeneration, BitsAndBytesConfig\n",
        "from transformers import AutoTokenizer, BitsAndBytesConfig\n",
        "from huggingface_hub import snapshot_download"
      ],
      "metadata": {
        "id": "m-oyWHHyj-YK",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721112286167,
          "user_tz": -330,
          "elapsed": 39953,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "m-oyWHHyj-YK",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"llava-hf/llava-v1.6-34b-hf\"\n",
        "local_dir = \"/content/llava-v1.6-34b-hf\"\n",
        "\n",
        "# Download the model\n",
        "snapshot_download(repo_id=model_name, local_dir=local_dir, ignore_patterns=[\"*.md\", \"*.txt\"])\n",
        "\n",
        "# Verify the download\n",
        "print(os.listdir(local_dir))"
      ],
      "metadata": {
        "id": "ZuAy0JdyPuS1"
      },
      "id": "ZuAy0JdyPuS1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specify how to quantize the model\n",
        "kwargs = {\"device_map\": \"auto\"}\n",
        "\n",
        "\n",
        "kwargs['quantization_config'] = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "processor = LlavaNextProcessor.from_pretrained(local_dir, token = \"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\")\n"
      ],
      "metadata": {
        "id": "zY0aw7h8jQsD",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721112782011,
          "user_tz": -330,
          "elapsed": 52448,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "zY0aw7h8jQsD",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LlavaNextForConditionalGeneration.from_pretrained(local_dir, low_cpu_mem_usage=True, **kwargs)\n"
      ],
      "metadata": {
        "id": "u_ZU4vjcjQkP"
      },
      "id": "u_ZU4vjcjQkP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "thZJEIwGjQb6"
      },
      "id": "thZJEIwGjQb6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare image and text prompt, using the appropriate prompt template\n",
        "#url = \"https://github.com/haotian-liu/LLaVA/blob/1a91fc274d7c35a9b50b3cb29c4247ae5837ce39/images/llava_v1_5_radar.jpg?raw=true\"\n",
        "#image = Image.open(requests.get(url, stream=True).raw)\n",
        "image = Image.open(r'/testings/invt1.jpg')\n",
        "question = \"\"\"give me buyer name, seller name, item description, item quantity, item price, the tax on the item, date of purchase, Invoice ID\n",
        "from the given invoice. report me these values in a json format\"\"\"\n",
        "prompt = f\"\"\"[INST]<image>\\n{question} [/INST]\"\"\"\n",
        "\n",
        "inputs = processor(prompt, image, return_tensors=\"pt\").to(\"cuda:0\")\n",
        "\n",
        "# autoregressively complete prompt\n",
        "output = model.generate(**inputs, max_new_tokens=600, do_sample = True,temperature = 0.2)\n",
        "\n",
        "print(processor.decode(output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "gtqLDABXjQT0"
      },
      "id": "gtqLDABXjQT0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "llava-next-hermes-34B"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}